{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_preprocessed_fill_missing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22151, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098</td>\n",
       "      <td>post remove request member hi welcome immediat...</td>\n",
       "      <td>suicidal-thoughts-and-self-harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116</td>\n",
       "      <td>hi nmtb thank post think lot people terrify st...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7189</td>\n",
       "      <td>hello cas fair anxiety depression work lot com...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4350</td>\n",
       "      <td>hey everyone discover another mum 's sister de...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9749</td>\n",
       "      <td>hi everyone guess title say really .. 28 year ...</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                       cleaned_text  \\\n",
       "0  11098  post remove request member hi welcome immediat...   \n",
       "1    116  hi nmtb thank post think lot people terrify st...   \n",
       "2   7189  hello cas fair anxiety depression work lot com...   \n",
       "3   4350  hey everyone discover another mum 's sister de...   \n",
       "4   9749  hi everyone guess title say really .. 28 year ...   \n",
       "\n",
       "                            target  \n",
       "0  suicidal-thoughts-and-self-harm  \n",
       "1                          anxiety  \n",
       "2                          anxiety  \n",
       "3                          anxiety  \n",
       "4                       depression  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data/train_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22151, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.40555438,  0.19110961,  0.14738172, ..., -0.621777  ,\n",
       "        -0.08748772, -0.46268186],\n",
       "       [-0.8397894 ,  0.08435682,  0.24780166, ..., -0.6236058 ,\n",
       "         0.18323515, -0.0878297 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "relationship-and-family-issues     6688\n",
       "anxiety                            6652\n",
       "depression                         5836\n",
       "ptsd-and-trauma                    1819\n",
       "suicidal-thoughts-and-self-harm    1156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 0, ..., 0, 2, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_classes = len(label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Fold 1/5\n",
      "Training models...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 17720, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86136\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\core.py:158: UserWarning: [21:09:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Accuracy: 0.6822, F1 Macro: 0.6050\n",
      "\n",
      "Processing Fold 2/5\n",
      "Training models...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 17721, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86136\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\core.py:158: UserWarning: [21:15:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Accuracy: 0.6937, F1 Macro: 0.6018\n",
      "\n",
      "Processing Fold 3/5\n",
      "Training models...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 17721, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86136\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\core.py:158: UserWarning: [21:21:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Accuracy: 0.6986, F1 Macro: 0.6121\n",
      "\n",
      "Processing Fold 4/5\n",
      "Training models...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.166806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 17721, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86136\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\core.py:158: UserWarning: [21:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Accuracy: 0.6966, F1 Macro: 0.6017\n",
      "\n",
      "Processing Fold 5/5\n",
      "Training models...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 17721, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86136\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\core.py:158: UserWarning: [21:34:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - Accuracy: 0.6916, F1 Macro: 0.6057\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.6926 (+/- 0.0057)\n",
      "Average F1 Macro: 0.6053 (+/- 0.0038)\n",
      "\n",
      "Training final ensemble on full dataset...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.231126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 22151, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86136\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\core.py:158: UserWarning: [21:40:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Initialize cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_macro_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_encoded)):\n",
    "    print(f\"\\nProcessing Fold {fold + 1}/5\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "    \n",
    "    # Calculate class weights\n",
    "    classes = np.unique(y_train)\n",
    "    class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "    sample_weights = np.array([class_weights[i] for i in y_train])\n",
    "    \n",
    "    # Initialize models with class weights\n",
    "    lgbm = LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        num_class=num_classes,\n",
    "        class_weight={i: w for i, w in enumerate(class_weights)},\n",
    "        random_state=42,\n",
    "        force_col_wise=True,\n",
    "        device='gpu'  # Enable GPU\n",
    "    )\n",
    "    \n",
    "    xgb = XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=num_classes,\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        tree_method='gpu_hist'  # Enable GPU\n",
    "    )\n",
    "    \n",
    "    cat = CatBoostClassifier(\n",
    "        loss_function='MultiClass',\n",
    "        class_weights=list(class_weights),\n",
    "        verbose=0,\n",
    "        random_state=42,\n",
    "        task_type='GPU'  # Enable GPU\n",
    "    )\n",
    "    \n",
    "    # Train models\n",
    "    print(\"Training models...\")\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    xgb.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "    cat.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    lgbm_proba = lgbm.predict_proba(X_val)\n",
    "    xgb_proba = xgb.predict_proba(X_val)\n",
    "    cat_proba = cat.predict_proba(X_val)\n",
    "    \n",
    "    # Ensemble predictions (average probabilities)\n",
    "    ensemble_proba = (lgbm_proba + xgb_proba + cat_proba) / 3\n",
    "    ensemble_preds = np.argmax(ensemble_proba, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    fold_acc = accuracy_score(y_val, ensemble_preds)\n",
    "    fold_f1 = f1_score(y_val, ensemble_preds, average='macro')\n",
    "    \n",
    "    accuracy_scores.append(fold_acc)\n",
    "    f1_macro_scores.append(fold_f1)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} - Accuracy: {fold_acc:.4f}, F1 Macro: {fold_f1:.4f}\")\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_scores):.4f} (+/- {np.std(accuracy_scores):.4f})\")\n",
    "print(f\"Average F1 Macro: {np.mean(f1_macro_scores):.4f} (+/- {np.std(f1_macro_scores):.4f})\")\n",
    "\n",
    "# Train final ensemble on full dataset for test set predictions\n",
    "print(\"\\nTraining final ensemble on full dataset...\")\n",
    "final_class_weights = compute_class_weight('balanced', classes=np.unique(y_encoded), y=y_encoded)\n",
    "final_sample_weights = np.array([final_class_weights[i] for i in y_encoded])\n",
    "\n",
    "final_lgbm = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=num_classes,\n",
    "    class_weight={i: w for i, w in enumerate(final_class_weights)},\n",
    "    random_state=42\n",
    ").fit(X, y_encoded)\n",
    "\n",
    "final_xgb = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=num_classes,\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ").fit(X, y_encoded, sample_weight=final_sample_weights)\n",
    "\n",
    "final_cat = CatBoostClassifier(\n",
    "    loss_function='MultiClass',\n",
    "    class_weights=list(final_class_weights),\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ").fit(X, y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test_preprocessed_fill_missing.csv')\n",
    "test_X = np.load('data/test_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for test set predictions:\n",
    "test_preds_lgbm = final_lgbm.predict_proba(test_X)\n",
    "test_preds_xgb = final_xgb.predict_proba(test_X)\n",
    "test_preds_cat = final_cat.predict_proba(test_X)\n",
    "ensemble_preds = (test_preds_lgbm + test_preds_xgb + test_preds_cat) / 3\n",
    "final_predictions = label_encoder.inverse_transform(np.argmax(ensemble_preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'target': final_predictions\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission_df.to_csv('data/submission_ensemble_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
